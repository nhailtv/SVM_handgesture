
# This file was generated by the Tkinter Designer by Parth Jadhav
# https://github.com/ParthJadhav/Tkinter-Designer


from pathlib import Path

# from tkinter import *
# Explicit imports to satisfy Flake8
from tkinter import Tk, Canvas, Entry, Text, Button, PhotoImage, Toplevel, Label
import cv2
import threading
import numpy as np
import mediapipe as mp
import pickle
import pandas as pd
import sys
from PIL import Image, ImageTk


OUTPUT_PATH = Path(__file__).parent
ASSETS_PATH = OUTPUT_PATH / Path(r"D:\HAND_GESTURE\Tkinker\build\assets\frame0")


def relative_to_assets(path: str) -> Path:
    return ASSETS_PATH / Path(path)


window = Tk()

window.geometry("1088x731")
window.configure(bg = "#000000")


canvas = Canvas(
    window,
    bg = "#000000",
    height = 731,
    width = 1088,
    bd = 0,
    highlightthickness = 0,
    relief = "ridge"
)

canvas.place(x = 0, y = 0)
canvas.create_rectangle(
    29.0,
    80.0,
    541.0,
    592.0,
    fill="#D9D9D9",
    outline="")

canvas.create_rectangle(
    554.0,
    80.0,
    1066.0,
    592.0,
    fill="#D9D9D9",
    outline="")

button_image_1 = PhotoImage(
    file=relative_to_assets("button_1.png"))

# --- Camera and Model Logic ---
camera_running = False
cap = None
thread_cam = None

# Load model only once
with open('d:/HAND_GESTURE/trained_models.pkl', 'rb') as f:
    model_data = pickle.load(f)
models = model_data['models']
scaler = model_data['scaler']
label_encoder = model_data['label_encoder']
feature_names = model_data['feature_names']
best_model = models['SVM'] if 'SVM' in models else list(models.values())[0]

mp_hands = mp.solutions.hands
mp_draw = mp.solutions.drawing_utils

def calculate_distance(p1, p2):
    return np.linalg.norm(np.array(p1) - np.array(p2))

def calculate_angle(p1, p2, p3):
    v1 = np.array(p1) - np.array(p2)
    v2 = np.array(p3) - np.array(p2)
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    if norm_v1 == 0 or norm_v2 == 0:
        return 0
    cos_angle = np.dot(v1, v2) / (norm_v1 * norm_v2)
    cos_angle = np.clip(cos_angle, -1, 1)
    return np.arccos(cos_angle)

def extract_features(landmarks):
    features = []
    wrist = landmarks[0]
    fingertips = [4, 8, 12, 16, 20]
    mcps = [1, 5, 9, 13, 17]
    finger_segments = [
        [1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12],
        [13, 14, 15, 16], [17, 18, 19, 20]
    ]
    for tip_idx in fingertips:
        features.append(calculate_distance(wrist, landmarks[tip_idx]))
    for i in range(len(fingertips)):
        for j in range(i+1, len(fingertips)):
            features.append(calculate_distance(landmarks[fingertips[i]], landmarks[fingertips[j]]))
    for mcp_idx in mcps:
        features.append(calculate_distance(wrist, landmarks[mcp_idx]))
    for finger in finger_segments:
        total_length = 0
        for i in range(len(finger)-1):
            total_length += calculate_distance(landmarks[finger[i]], landmarks[finger[i+1]])
        features.append(total_length)
        for i in range(len(finger)-1):
            features.append(calculate_distance(landmarks[finger[i]], landmarks[finger[i+1]]))
    for finger in finger_segments:
        for i in range(1, len(finger)-1):
            features.append(calculate_angle(landmarks[finger[i-1]], landmarks[finger[i]], landmarks[finger[i+1]]))
    features.append(calculate_angle(landmarks[4], landmarks[0], landmarks[8]))
    features.append(calculate_angle(landmarks[8], landmarks[0], landmarks[12]))
    features.append(calculate_angle(landmarks[12], landmarks[0], landmarks[16]))
    features.append(calculate_angle(landmarks[16], landmarks[0], landmarks[20]))
    palm_points = [0, 1, 5, 9, 13, 17]
    palm_center = np.mean([landmarks[i] for i in palm_points], axis=0)
    for tip_idx in fingertips:
        features.append(calculate_distance(palm_center, landmarks[tip_idx]))
    tip_distances = [calculate_distance(wrist, landmarks[tip_idx]) for tip_idx in fingertips]
    features.append(np.var(tip_distances))
    features.append(np.mean(tip_distances))
    features.append(np.std(tip_distances))
    wrist_to_middle = np.array(landmarks[9]) - np.array(wrist)
    features.append(np.arctan2(wrist_to_middle[1], wrist_to_middle[0]))
    features.append(np.arctan2(wrist_to_middle[2], np.sqrt(wrist_to_middle[0]**2 + wrist_to_middle[1]**2)))
    max_spread = 0
    for i in range(len(fingertips)):
        for j in range(i+1, len(fingertips)):
            dist = calculate_distance(landmarks[fingertips[i]], landmarks[fingertips[j]])
            max_spread = max(max_spread, dist)
    features.append(max_spread)
    features.append(calculate_distance(landmarks[4], landmarks[20]))
    z_coords = [landmarks[i][2] for i in range(21)]
    features.append(np.mean(z_coords))
    features.append(np.std(z_coords))
    features.append(max(z_coords) - min(z_coords))
    return np.array(features).reshape(1, -1)

def run_camera():
    global camera_running, cap, normal_img_on_canvas, model_img_on_canvas
    cap = cv2.VideoCapture(0)
    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)
    while camera_running:
        ret, frame = cap.read()
        if not ret:
            break
        # Flip camera horizontally for natural view
        frame = cv2.flip(frame, 1)
        # Normal camera rectangle (left)
        normal_frame = cv2.resize(frame, (512, 512))
        # Model camera rectangle (right)
        model_frame = frame.copy()
        img_rgb = cv2.cvtColor(model_frame, cv2.COLOR_BGR2RGB)
        results = hands.process(img_rgb)
        gesture = ""
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                lm = []
                h, w, _ = model_frame.shape
                for i in range(21):
                    x = hand_landmarks.landmark[i].x * w
                    y = hand_landmarks.landmark[i].y * h
                    z = hand_landmarks.landmark[i].z * w
                    lm.append([x, y, z])
                feats = extract_features(lm)
                feats_df = pd.DataFrame(feats, columns=feature_names)
                feats_scaled = scaler.transform(feats_df)
                pred = best_model.predict(feats_scaled)[0]
                gesture = label_encoder.classes_[pred]
                mp_draw.draw_landmarks(model_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                cv2.putText(model_frame, f'Gesture: {gesture}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 3)
        model_frame = cv2.resize(model_frame, (512, 512))

        # Convert BGR to RGB for Tkinter
        normal_img = cv2.cvtColor(normal_frame, cv2.COLOR_BGR2RGB)
        model_img = cv2.cvtColor(model_frame, cv2.COLOR_BGR2RGB)
        normal_img_pil = ImageTk.PhotoImage(Image.fromarray(normal_img))
        model_img_pil = ImageTk.PhotoImage(Image.fromarray(model_img))

        # Display on canvas rectangles
        # Left rectangle: (29,80)-(541,592), right rectangle: (554,80)-(1066,592)
        canvas.create_image(29, 80, anchor='nw', image=normal_img_pil, tag='normal_cam')
        canvas.create_image(554, 80, anchor='nw', image=model_img_pil, tag='model_cam')
        # Keep reference to avoid garbage collection
        canvas.normal_img_ref = normal_img_pil
        canvas.model_img_ref = model_img_pil

        # Update the canvas
        window.update_idletasks()
        window.update()
    if cap:
        cap.release()
    # Remove images from canvas when stopped
    canvas.delete('normal_cam')
    canvas.delete('model_cam')

def start_camera():
    global camera_running, thread_cam, loading_popup
    if not camera_running:
        # Hiển thị popup loading
        loading_popup = Toplevel(window)
        loading_popup.title("Đang khởi động camera...")
        loading_popup.geometry("300x100")
        loading_popup.resizable(False, False)
        loading_popup.grab_set()
        Label(loading_popup, text="Đang khởi động camera, vui lòng chờ...", font=("Arial", 12)).pack(expand=True)
        window.update_idletasks()
        def start_and_close():
            global camera_running, thread_cam
            camera_running = True
            thread_cam = threading.Thread(target=run_camera_with_popup_close)
            thread_cam.start()
        window.after(100, start_and_close)

def run_camera_with_popup_close():
    # Chạy camera như cũ, nhưng đóng popup loading NGAY SAU KHI camera khởi động xong (sau khi mở camera thành công)
    global camera_running, cap, loading_popup
    cap = cv2.VideoCapture(0)
    # Đóng popup ngay khi camera mở xong
    if 'loading_popup' in globals() and loading_popup.winfo_exists():
        loading_popup.destroy()
    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)
    while camera_running:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.flip(frame, 1)
        normal_frame = cv2.resize(frame, (512, 512))
        model_frame = frame.copy()
        img_rgb = cv2.cvtColor(model_frame, cv2.COLOR_BGR2RGB)
        results = hands.process(img_rgb)
        gesture = ""
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                lm = []
                h, w, _ = model_frame.shape
                for i in range(21):
                    x = hand_landmarks.landmark[i].x * w
                    y = hand_landmarks.landmark[i].y * h
                    z = hand_landmarks.landmark[i].z * w
                    lm.append([x, y, z])
                feats = extract_features(lm)
                feats_df = pd.DataFrame(feats, columns=feature_names)
                feats_scaled = scaler.transform(feats_df)
                pred = best_model.predict(feats_scaled)[0]
                gesture = label_encoder.classes_[pred]
                mp_draw.draw_landmarks(model_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
                cv2.putText(model_frame, f'Gesture: {gesture}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 3)
        model_frame = cv2.resize(model_frame, (512, 512))
        normal_img = cv2.cvtColor(normal_frame, cv2.COLOR_BGR2RGB)
        model_img = cv2.cvtColor(model_frame, cv2.COLOR_BGR2RGB)
        normal_img_pil = ImageTk.PhotoImage(Image.fromarray(normal_img))
        model_img_pil = ImageTk.PhotoImage(Image.fromarray(model_img))
        canvas.create_image(29, 80, anchor='nw', image=normal_img_pil, tag='normal_cam')
        canvas.create_image(554, 80, anchor='nw', image=model_img_pil, tag='model_cam')
        canvas.normal_img_ref = normal_img_pil
        canvas.model_img_ref = model_img_pil
        window.update_idletasks()
        window.update()
    if cap:
        cap.release()
    canvas.delete('normal_cam')
    canvas.delete('model_cam')

def stop_camera():
    global camera_running
    camera_running = False

def minimize_window():
    window.iconify()

def close_program():
    stop_camera()
    window.destroy()
    sys.exit(0)

button_1 = Button(
    image=button_image_1,
    borderwidth=0,
    highlightthickness=0,
    command=start_camera,
    relief="flat"
)
button_1.place(
    x=360.0,
    y=609.0,
    width=181.0,
    height=80.0
)

button_image_2 = PhotoImage(
    file=relative_to_assets("button_2.png"))

button_2 = Button(
    image=button_image_2,
    borderwidth=0,
    highlightthickness=0,
    command=minimize_window,
    relief="flat"
)
button_2.place(
    x=958.0,
    y=15.0,
    width=45.0,
    height=41.0
)

button_image_3 = PhotoImage(
    file=relative_to_assets("button_3.png"))

button_3 = Button(
    image=button_image_3,
    borderwidth=0,
    highlightthickness=0,
    command=close_program,
    relief="flat"
)
button_3.place(
    x=1011.0,
    y=15.0,
    width=38.0,
    height=41.0
)

image_image_1 = PhotoImage(
    file=relative_to_assets("image_1.png"))
image_1 = canvas.create_image(
    547.0,
    39.0,
    image=image_image_1
)

button_image_4 = PhotoImage(
    file=relative_to_assets("button_4.png"))

button_4 = Button(
    image=button_image_4,
    borderwidth=0,
    highlightthickness=0,
    command=stop_camera,
    relief="flat"
)
button_4.place(
    x=554.0,
    y=610.0,
    width=182.0,
    height=79.0
)
window.resizable(False, False)
window.mainloop()
